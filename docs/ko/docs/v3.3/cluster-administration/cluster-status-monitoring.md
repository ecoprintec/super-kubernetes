---
title: "클러스터 상태 모니터링"
keywords: "Kubernetes, Super Kubenetes, status, monitoring"
description: "Monitor how a cluster is functioning based on different metrics, including physical resources, etcd, and API server."
linkTitle: "Cluster Status Monitoring"
weight: 8200
---

Super Kubenetes는 클러스터의 CPU, 메모리, 네트워크 및 디스크와 같은 관련 메트릭에 대한 모니터링을 제공합니다. 또한 기록 모니터링 데이터를 검토하고 **클러스터 상태**에서 사용량에 따라 다양한 지표별로 노드를 정렬할 수 있습니다.

## 사전 준비

**클러스터 관리** 권한을 포함하여 역할이 부여된 사용자가 필요합니다. 예를 들어 콘솔에 `admin`으로 직접 로그인하거나 권한이 있는 새 역할을 생성하여 사용자에게 할당할 수 있습니다.

## 클러스터 상태 모니터링

1. 왼쪽 상단 모서리에서 **플랫폼**을 클릭하고 **클러스터 관리**를 선택합니다.

2. 가져온 멤버 클러스터와 함께 [멀티 클러스터 기능](../../multicluster-management/)을 활성화한 경우 특정 클러스터를 선택하여 해당 애플리케이션 리소스를 볼 수 있습니다. 기능을 활성화하지 않은 경우 다음 단계를 직접 참고하세요.

3. **클러스터 노드 상태**, **컴포넌트 상태**, **클러스터 리소스 사용량**, **etcd 모니터링** 및 **서비스 컴포넌트 모니터링**을 포함한 클러스터 상태 모니터링에 대한 전반적인 것을 확인하려면 **모니터링 및 경고**에서 **클러스터 상태**를 선택하세요.

### 클러스터 노드 상태

1. **클러스터 노드 상태**는 활성 노드를 별도로 표시하여 모든 노드의 상태를 표시합니다. **클러스터 노드** 페이지로 이동하여 **노드 온라인 상태**를 클릭하여 모든 노드의 실시간 리소스 사용량을 볼 수 있습니다.

2. **클러스터 노드**에서 노드 이름을 클릭하여 **리소스 사용량**, **할당된 리소스** 및 **헬스 상태**를 포함한 **실행 상태**의 사용량에 대한 세부 정보를 볼 수 있습니다.

3. **모니터링** 탭을 클릭하여 **CPU 사용량**, **평균 CPU 로드**, **메모리 사용량**, **디스크 사용량**, **Inode 사용량**, **IOPS**, **디스크 처리량** 및 **네트워크 대역폭**을 포함한 다양한 메트릭을 기반으로 특정 기간 동안 노드가 어떻게 작동하지 확인 할 수 있습니다. 

  <div className="notices tip">
    <p>Tip</p>
    <div>
      우측 상단 모서리에 있는 드롭다운 목록에서 시간 범위를 커스텀하여 기록 데이터를 볼 수 있습니다.
    </div>
  </div>

### 컴포넌트 상태

Super Kubenetes는 클러스터에 있는 다양한 서비스 컴포넌트의 상태를 모니터링합니다. 주요 컴포넌트가 오작동할 경우 시스템을 사용할 수 없게 될 수 있습니다. Super Kubenetes의 모니터링 메커니즘은 컴포넌트에 장애가 발생할 경우 발생하는 문제를 플랫폼이 테넌트에 알릴 수 있도록 하여 테넌트가 문제를 신속하게 찾고 해당 조치를 취할 수 있도록 합니다.

1. **클러스터 상태** 페이지에서 **컴포넌트 상태** 아래의 컴포넌트를 클릭하여 해당 상태를 확인합니다.

2. 이 부분에 모든 컴포넌트가 나열되어 있는 것을 볼 수 있습니다. 녹색으로 표시된 컴포넌트는 정상적으로 작동하는 컴포넌트이고 주황색으로 표시된 컴포넌트는 잠재적인 문제를 나타내므로 특별한 주의가 필요합니다.

   <div className="notices tip">
     <p>Tip</p>
     <div>
       주황색으로 표시된 컴포넌트는 일정 시간이 지나면 녹색으로 바뀔 수 있으며, 그 이유는 이미지 풀링 재시도 또는 파드 재생성과 같이 여러가지 경우가 있습니다. 컴포넌트를 클릭하여 해당 서비스 세부 정보를 볼 수 있습니다.     
      </div>
   </div>

### 클러스터 리소스 사용량

**클러스터 리소스 사용량**은 클러스터에 있는 모든 노드의 **CPU 사용량**, **메모리 사용량**, **디스크 사용량**, **파드**를 포함한 정보를 표시합니다. 왼쪽의 원형 차트를 클릭하여 지표를 전환하고 우측의 꺾은 선형 차트에서 특정 기간 동안의 추세를 보여줍니다.

## 물리적 자원 모니터링

**물리적 리소스 모니터링**의 모니터링 데이터는 사용자가 물리적 리소스를 더 잘 관찰하고 리소스 및 클러스터 성능에 대한 일반적인 표준을 설정하는 데 도움이 됩니다. Super Kubenetes를 사용하면 **CPU 사용량**, **메모리 사용량**, **평균 CPU 로드(1분/5분/15분)**, **디스크 사용량**, **Inode 사용량**, **디스크 처리량(읽기/쓰기)**, **IOPS(읽기/쓰기)**, **네트워크 대역폭** 및 **파드 상태**를 포함한 지난 7일 동안의 클러스터 모니터링 데이터를 볼 수 있습니다. 시간 범위 및 시간 간격을 커스텀하여 Super Kubenetes에서 물리적 리소스에 대한 모니터링 이력 데이터를 볼 수 있습니다. 다음 섹션에서는 각 모니터링 지표를 간략하게 소개합니다.

### CPU 사용량

CPU 사용량은 특정 기간 동안 CPU 리소스가 어떻게 사용되는지 보여줍니다. 특정 기간 동안 플랫폼의 CPU 사용량이 급증하는 것을 발견하면 먼저 CPU 리소스를 가장 많이 차지하는 프로세스를 찾아야 합니다. 예를 들어 Java 응용 프로그램의 경우 코드에서 메모리 누수 또는 무한 루프의 경우 CPU 사용량 급증을 예상할 수 있습니다.

### 메모리 사용량

메모리는 CPU와의 통신을 위한 브리지 역할을 하는 기계의 중요한 컴포넌트 중 하나입니다. 따라서 메모리의 성능은 기계에 큰 영향을 미칩니다. 데이터 로딩, 스레드 동시성 및 I/O 버퍼링은 모두 프로그램이 실행될 때 메모리에 종속됩니다. 사용 가능한 메모리의 크기는 프로그램이 정상적으로 실행될 수 있는지 여부와 작동 방식을 결정합니다. 메모리 사용량은 클러스터 내에서 메모리 리소스가 전체적으로 사용되는 방식을 반영하며 주어진 순간에 사용 가능한 메모리의 백분율로 표시됩니다.

### 평균 CPU 로드

평균 CPU 로드는 단위 시간당 실행 가능한 상태와 중단 불가능한 상태인 시스템의 평균 프로세스 수입니다. 즉, 활성 프로세스의 평균 수입니다. 평균 CPU 로드와 CPU 사용량 사이에는 직접적인 관계가 없습니다. 이상적으로는 평균 로드는 CPU 개수와 같아야 합니다. 따라서 평균 부하를 볼 때 CPU 개수를 고려해야 합니다. 평균 부하가 CPU 개수보다 클 경우 시스템이 과부하됩니다.

Super Kubenetes는 사용자에게 평균 로드를 볼 수 있는 세 가지 시간(1분, 5분, 15분)을 제공합니다. 일반적으로 평균 CPU 로드를 포괄적으로 이해하려면 모든 항목을 검토하는 것이 좋습니다.

- 1분 / 5분 / 15분의 곡선이 일정 기간 동안 유사하면 클러스터의 CPU 부하가 비교적 안정적이라고 볼 수 있습니다.
- 특정 시간 또는 특정 시점에서 1분 동안의 값이 15분 동안의 값보다 훨씬 크면 최근 1분 동안 부하가 증가하고 있음을 의미하므로 계속 관찰해야 합니다. 1분 동안의 값이 CPU 개수를 초과하면 시스템이 과부하되었음을 의미할 수 있습니다. 문제의 원인을 자세히 분석해야 합니다.
- 반대로 특정 기간 또는 특정 시점에서 1분 동안의 값이 15분 동안의 값보다 훨씬 작으면 시스템의 부하가 최근 1분 동안 감소하고 있으며 높은 부하가 이전 15분 동안 생성되었다는 것을 의미합니다.

### 디스크 사용량

`스테이트풀셋` 및 `데몬셋`와 같은 Super Kubenetes 워크로드는 모두 영구 볼륨에 의존합니다. 일부 컴포넌트 및 서비스에는 영구 볼륨도 필요합니다. 이러한 백엔드 스토리지는 블록 스토리지 또는 네트워크 공유 스토리지와 같은 디스크에 의존합니다. 이와 관련하여 디스크 사용량에 대한 실시간 모니터링 환경을 제공하는 것은 데이터의 높은 신뢰성을 유지하는 데 중요한 부분입니다.

Linux 시스템의 일상적인 관리에서 플랫폼 관리자는 디스크 공간 부족으로 인해 데이터 손실 또는 시스템 충돌이 발생할 수 있습니다. 클러스터 관리의 필수적인 부분으로서 시스템의 디스크 사용량에 세심한 주의를 기울여야 하며 파일 시스템이 가득 차거나 남용되지 않도록 해야 합니다. 디스크 사용량에 대한 기록 데이터를 모니터링하여 지정된 기간 동안 디스크가 어떻게 사용되었는지 평가할 수 있습니다. 디스크 사용량이 많은 경우 불필요한 이미지나 컨테이너를 정리하여 디스크 공간을 확보할 수 있습니다.

### 아이노드 사용

각 파일에는 파일 작성자 및 생성 날짜와 같은 파일의 메타 정보를 저장하는 데 사용되는 inode가 있어야 합니다. inode는 또한 하드 디스크 공간을 소비하며 수많은 작은 캐시 파일은 쉽게 inode 리소스를 고갈시킬 수 있습니다. 그리고 inode가 모두 사용되었지만 하드 디스크가 가득 차지 않는 경우가 있는데, 이 경우 하드 디스크에 새 파일을 만들 수 없습니다.

Super Kubenetes에서 inode 사용량을 모니터링하면 클러스터 inode 사용량을 명확하게 볼 수 있으므로 이러한 상황을 미리 감지하는 데 도움이 됩니다. 이 메커니즘은 사용자에게 시간 내에 임시 파일을 정리하라는 메시지를 표시하여 inode 고갈로 인해 클러스터가 작동하지 않는 것을 방지합니다.

### 디스크 처리량

디스크 처리량 및 IOPS 모니터링은 디스크 모니터링의 필수 불가결한 부분이며, 이는 클러스터 관리자가 클러스터의 전체 성능을 최적화하기 위해 데이터 레이아웃 및 기타 관리 활동을 조정하는 데 편리합니다. 디스크 처리량은 디스크 전송 데이터 스트림의 속도(MB/s로 표시)를 나타내며 전송 데이터는 데이터 읽기 및 쓰기의 합계입니다. 불연속 데이터의 큰 블록이 전송될 때 이 표시기는 참조용으로 매우 중요합니다.

### IOPS

**IOPS(Input/Output Operations Per Second)**는 초당 읽기 및 쓰기 작업 수의 성능 측정치를 나타냅니다. 특히 디스크의 IOPS는 초당 연속 읽기 및 쓰기 수의 합계입니다. 이 표시기는 불연속 데이터의 작은 블록이 전송될 때 참조용으로 매우 중요합니다.

### 네트워크 대역폭

네트워크 대역폭은 Mbps(초당 메가비트)로 표시되는 네트워크 카드의 초당 데이터 수신 또는 전송할 수 있는 용량을 의미합니다.

### 파드 상태

파드 상태는 **실행 중**, **완료** 및 **주의**을 포함하여 다양한 상태의 총 파드 수를 표시합니다. **완료** 태그가 지정된 파드는 일반적으로 Job 또는 CronJob을 나타냅니다. 비정상적인 상태를 의미하는 **주의**으로 표시된 파드의 수는 특별한 주의가 필요합니다.

## etcd 모니터링

etcd 모니터링은 etcd를 더 잘 사용하는 데 도움이 됩니다. 특히 성능 문제를 찾는데 아주 유용합니다. etcd 서비스는 기본적으로 메트릭 인터페이스를 제공하고 Super Kubenetes 모니터링 시스템은 기본 데이터를 표시하기 위해 그래픽적이며 반응이 빠른 대시보드를 제공합니다.

  <table>
  <thead>
  <tr>
    <th>
      지표
    </th>
    <th>
      설명
    </th>
  </tr>
  </thead>
  <tbody>
  <tr>
    <td>
      서비스 상태
    </td>
    <td>
      <strong>리더 존재</strong>는 멤버에게 리더가 있는지 여부를 나타냅니다. 회원에게 리더가 없으면 완전히 사용할 수 없습니다. 클러스터의 모든 멤버에 리더가 없으면 전체 클러스터를 완전히 사용할 수 없습니다.<br>
      - <strong>1시간 동안의 리더 변경</strong>은 1시간 동안 클러스터 멤버가 본 리더 변경 수를 나타냅니다. 빈번한 리더 변경은 etcd의 성능에 상당한 영향을 미칩니다. 또한 네트워크 연결 문제 또는 etcd 클러스터에 가해지는 과도한 로드로 인해 리더가 불안정함을 보여줍니다.
    </td>
  </tr>
  <tr>
    <td>
      DB 크기
    </td>
    <td>
      etcd의 기본 데이터베이스 크기(MiB)입니다. 현재 그래프는 etcd의 각 멤버 데이터베이스의 평균 크기를 보여줍니다.
    </td>
  </tr>
  <tr>
    <td>
      클라이언트 트래픽
    </td>
    <td>
      여기에는 gRPC 클라이언트로 보낸 총 트래픽과 gRPC 클라이언트로부터 받은 총 트래픽이 포함됩니다. 지표에 대한 자세한 내용은 <a href="https://github.com/etcd-io/etcd/blob/v3.2.17/Documentation/metrics.md#network" target="_blank" rel="noopener noreferrer">etcd 네트워크</a>를 참고하세요. 
    </td>
  </tr>
  <tr>
    <td>
      gRPC 스트림 메시지
    </td>
    <td>
      gRPC 스트리밍 메시지 수신 속도 및 서버 측 전송 속도는 클러스터에서 대규모 데이터 읽기 및 쓰기 작업이 발생하는지 여부를 반영합니다. 지표에 대한 자세한 내용은 <a href="https://github.com/grpc-ecosystem/go-grpc-prometheus#counters" target="_blank" rel="noopener noreferrer">go-grpc-prometheus</a>를 참고하세요. 
    </td>
  </tr>
  <tr>
    <td>
      WAL Fsync
    </td>
    <td>
      fsync를 호출하는 WAL의 지연 시간입니다. <code>wal_fsync</code>는 etcd가 로그 항목을 적용하기 전에 디스크에 유지할 때 호출됩니다. 지표에 대한 자세한 내용은 <a href="https://etcd.io/docs/v3.3.12/metrics/#grpc-requests" target="_blank" rel="noopener noreferrer">etcd Disk</a>를 참고하세요. 
    </td>
  </tr>
  <tr>
    <td>
      DB Fsync
    </td>
    <td>
      백엔드 호출의 전송 지연 분포입니다. etcd가 디스크에 가장 최근의 증분 스냅샷을 제출하면 <code>backend_commit</code>이 호출됩니다. 디스크 작업의 긴 대기 시간(긴 WAL 로그 동기화 시간 또는 라이브러리 동기화 시간)은 일반적으로 디스크 문제를 나타내므로 요청 대기 시간이 길거나 클러스터가 불안정해질 수 있습니다. 지표에 대한 자세한 내용은 <a href="https://etcd.io/docs/v3.3.12/metrics/#grpc-requests" target="_blank" rel="noopener noreferrer">etcd Disk</a>를 참고하세요. 
    </td>
  </tr>
  <tr>
    <td>
      Raft 제안
    </td>
    <td>
      - <strong>제안 커밋 비율</strong>은 컨센서스 제안이 커밋된 비율을 기록합니다. 클러스터가 정상이면 이 표시기는 시간이 지남에 따라 증가해야 합니다. etcd 클러스터의 여러 정상 멤버는 동시에 다른 일반 제안을 가질 수 있습니다. 단일 멤버와 해당 리더 사이에 지속적으로 큰 지연이 발생하면 해당 멤버가 느리거나 비정상임을 나타냅니다.<br>
      - <strong>제안 적용 비율</strong>은 적용된 합의 제안의 총 비율을 기록합니다. etcd 서버는 커밋된 각 제안을 비동기적으로 적용합니다. <strong>제안 커밋 비율</strong>과 <strong>제안 적용 비율</strong> 간의 차이는 일반적으로 작아야 합니다(높은 로드에서도 수천 개에 불과). 둘 사이의 차이가 계속 증가하면 etcd 서버가 과부하되었음을 나타냅니다. 이는 광범위한 쿼리 또는 대규모 txn 작업과 같은 대규모 쿼리를 사용할 때 발생할 수 있습니다.<br>
      - <strong>제안 실패율</strong>은 일반적으로 두 가지 문제와 관련된 실패한 제안의 총 비율을 기록합니다. 즉, 리더 선출과 관련된 일시적인 실패 또는 클러스터의 정족수 손실로 인한 더 긴 가동 중지 시간입니다.<br>
      - <strong>제안 보류 합계</strong>는 보류 중인 제안서의 현재 수를 기록합니다. 보류 중인 제안서의 증가는 클라이언트 부하가 높거나 멤버가 제안서를 제출할 수 없음을 나타냅니다.<br>
      현재 대시보드에 표시되는 데이터는 etcd 멤버의 평균 크기입니다. 이러한 지표에 대한 자세한 내용은 <a href="https://etcd.io/docs/v3.3.12/metrics/#server" target="_blank" rel="noopener noreferrer">etcd Server</a>를 참고하세요. 
    </td>
  </tr>
  </tbody>
  </table>

## API 서버 모니터링

[API 서버](https://kubernetes.io/docs/concepts/overview/kubernetes-api/)는 쿠버네티스 클러스터의 모든 컴포넌트 상호 작용을 위한 허브입니다. 다음 표에는 API 서버에 대해 모니터링되는 주요 지표가 나열되어 있습니다.

  <table>
  <thead>
  <tr>
    <th>
      지표
    </th>
    <th>
      설명
    </th>
  </tr>
  </thead>
  <tbody>
  <tr>
    <td>
      요청 대기 시간
    </td>
    <td>
      HTTP 요청 방법으로 분류되며 리소스 요청 응답의 대기 시간(밀리초)입니다.
    </td>
  </tr>
  <tr>
    <td>
      초당 요청
    </td>
    <td>
      초당 kube-apiserver가 수락한 요청 수입니다.
    </td>
  </tr>
  </tbody>
  </table>

## 스케줄러 모니터링

[스케줄러](https://Kubernetes.io/docs/reference/command-line-tools-reference/kube-scheduler/)는 새로 생성된 파드의 쿠버네티스 API를 모니터링하고 이러한 새 파드가 실행되는 노드를 결정합니다. 수집된 리소스의 가용성 및 Pod의 리소스 요구 사항을 포함하여 사용 가능한 데이터를 기반으로 이러한 결정을 내립니다. 예약 지연에 대한 데이터를 모니터링하면 스케줄러가 직면한 모든 지연을 확인할 수 있습니다.

  <table>
  <thead>
  <tr>
    <th>
      지표
    </th>
    <th>
      설명
    </th>
  </tr>
  </thead>
  <tbody>
  <tr>
    <td>
      시도 빈도
    </td>
    <td>
      예약 성공, 오류 및 실패 횟수를 포함합니다.
    </td>
  </tr>
  <tr>
    <td>
      시도율
    </td>
    <td>
      성공, 오류 및 실패의 일정 비율을 포함합니다.
    </td>
  </tr>
  <tr>
    <td>
      예약 지연
    </td>
    <td>
      스케줄링 알고리즘 지연과 바인딩 지연의 합인 종단 간 스케줄링 지연
    </td>
  </tr>
  </tbody>
  </table>

## 리소스 사용량 순위

CPU 사용량, 평균 CPU 로드, 메모리 사용량, 디스크 사용량, inode 사용량 및 Pod 사용량과 같은 지표를 기준으로 노드를 오름차순 및 내림차순으로 정렬할 수 있습니다. 이를 통해 관리자는 잠재적인 문제를 신속하게 찾거나 노드의 불충분한 리소스를 식별할 수 있습니다.
